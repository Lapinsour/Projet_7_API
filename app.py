import os
import pickle
from flask import Flask, request, jsonify

# Charger le mod√®le
MODEL_PATH = "best_model.pkl"
if os.path.exists(MODEL_PATH):
    with open(MODEL_PATH, "rb") as f:
        model = pickle.load(f)
else:
    model = None  # Evite que l'API crashe si le mod√®le est absent

app = Flask(__name__)

@app.route('/predict', methods=['POST']) #L'API attend une requ√™te POSTE √† son url/predict. 
def predict(): #Lorsqu'elle re√ßoit une requ√™te POST, l'API renvoie le r√©sultat de la fonction predict().
    try:
        data = request.get_json() #Les donn√©es re√ßues sont en json.
        print("üöÄ Donn√©es re√ßues:", data)  # Log des donn√©es re√ßues

        if not data:
            return jsonify({"error": "No data received"}), 400

        # V√©rifie que le mod√®le est charg√©
        if model is None:
            return jsonify({"error": "Model not found"}), 500

        # Convertir les donn√©es en DataFrame si besoin (pandas)
        import pandas as pd
        df = pd.DataFrame([data]) #Les donn√©es sont converties en df pandas parce que c'est ce qu'attend le mod√®le. 

        # Pr√©diction
        prediction = model.predict(df)
        print("üéØ Pr√©diction:", prediction.tolist())  # Log des pr√©dictions

        return jsonify({"prediction": prediction.tolist()})

    except Exception as e:
        print("‚ùå Erreur:", str(e))  # Log des erreurs
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
